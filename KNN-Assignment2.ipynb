{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance \n",
    "metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65b16f3",
   "metadata": {},
   "source": [
    "#### Manhattan Distance is the L1 norm form (L1 norm is the sum of the magnitude of vectors in space), while Euclidean Distance is L2 Norm form (The L2 norm calculates the distance of the vector coordinate from the origin of the vector space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ea5cab",
   "metadata": {},
   "source": [
    "#### We don't use Manhattan Distance, because it calculates distance horizontally or vertically only. It has dimension restrictions. On the other hand, the Euclidean metric can be used in any space to calculate distance. Since the data points can be represented in any dimension, it is a more viable option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe60a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be \n",
    "used to determine the optimal k value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09016ca",
   "metadata": {},
   "source": [
    "#### Defining k can be a balancing act as different values can lead to overfitting or underfitting. Lower values of k can have high variance, but low bias, and larger values of k may lead to high bias and lower variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ab152",
   "metadata": {},
   "source": [
    "#### The choice of k will largely depend on the input data as data with more outliers or noise will likely perform better with higher values of k. Overall, it is recommended to have an odd number for k to avoid ties in classification, and cross-validation tactics can help you choose the optimal k for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25628bc9",
   "metadata": {},
   "source": [
    "-- use Hypeparameter Tuning for optimum k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deaca20",
   "metadata": {},
   "source": [
    "-- The optimal K value usually found is the square root of N, where N is the total number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In \n",
    "what situations might you choose one distance metric over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209928e2",
   "metadata": {},
   "source": [
    "### for high dimentionality, we use Manhattan distance metric in KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917807b",
   "metadata": {},
   "source": [
    "#### We mean by the 'best distance metric' (in this review) is the one that allows the KNN to classify test examples with the highest precision, recall and accuracy, i.e. the one that gives best performance of the KNN in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect \n",
    "the performance of the model? How might you go about tuning these hyperparameters to improve \n",
    "model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee7b1b7",
   "metadata": {},
   "source": [
    "-- n_neighbors (dafault 5): Number of neighbors to use by default for kneighbors queries\n",
    "    \n",
    "-- algorithm{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’ : Algorithm used to compute the nearest neighbors:\n",
    "        \n",
    "-- Power parameter p (default 2): Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What \n",
    "techniques can be used to optimize the size of the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f5bb1",
   "metadata": {},
   "source": [
    "#### KNN works well with smaller dataset because it is a lazy learner. It needs to store all the data and then makes decision only at run time. It needs to calculate the distance of a given point with all other points. So if dataset is large, there will be a lot of processing which may adversely impact the performance of the algorithm. \n",
    "\n",
    "KNN is also very sensitive to noise in the dataset. If the dataset is large, there are chances of noise in the dataset which adversely affect the performance of KNN algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7bd50e",
   "metadata": {},
   "source": [
    "#### we can use BallTree and KD Tree to get the nearby data from all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638fc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you \n",
    "overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f36f3d",
   "metadata": {},
   "source": [
    "#### KNN is sensitive to outliers and missing values and hence we first need to impute the missing values and get rid of the outliers before applying the KNN algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
