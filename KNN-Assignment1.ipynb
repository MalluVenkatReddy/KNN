{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf956403",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bce01d",
   "metadata": {},
   "source": [
    "#### The abbreviation KNN stands for “K-Nearest Neighbour”. It is a supervised machine learning algorithm. The algorithm can be used to solve both classification and regression problem statements. The number of nearest neighbours to a new unknown variable that has to be predicted or classified is denoted by the symbol 'K'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490de22e",
   "metadata": {},
   "source": [
    "#### The choice of k will largely depend on the input data as data with more outliers or noise will likely perform better with higher values of k. Overall, it is recommended to have an odd number for k to avoid ties in classification, and cross-validation tactics can help you choose the optimal k for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75122de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef790c",
   "metadata": {},
   "source": [
    "#### The key differences are: KNN regression tries to predict the value of the output variable by using a local average. KNN classification attempts to predict the class to which the output variable belong by computing the local probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36c3bb",
   "metadata": {},
   "source": [
    "#### Train the model on the entire dataset.\n",
    "Test the model on the same dataset, and evaluate how well we did by comparing the predicted response values with the true response values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8efec",
   "metadata": {},
   "source": [
    "-- For classification, use accuracy_score to check performance\n",
    "\n",
    "-- For Regression, use r2_score to check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f1fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc9d6a",
   "metadata": {},
   "source": [
    "#### The “Curse of Dimensionality” is a tongue in cheek way of stating that there's a ton of space in high-dimensional data sets. The size of the data space grows exponentially with the number of dimensions. This means that the size of your data set must also grow exponentially in order to keep the same density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c1f18d",
   "metadata": {},
   "source": [
    "#### Each sample's missing values are imputed using the mean/median value of the 'k'-neighbors found in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74529ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for \n",
    "which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082997d7",
   "metadata": {},
   "source": [
    "-- For classification, use accuracy_score to check performance\n",
    "\n",
    "-- For Regression, use r2_score to check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5294c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, \n",
    "and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331889d5",
   "metadata": {},
   "source": [
    "#### Advantages of KNN\n",
    "\n",
    "-- No Training Period: KNN is called Lazy Learner (Instance based learning). \n",
    "    \n",
    "-- Since the KNN algorithm requires no training before making predictions, new data can be added seamlessly which will not impact the accuracy of the algorithm.\n",
    "\n",
    "-- KNN is very easy to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b75d83f",
   "metadata": {},
   "source": [
    "#### Dis Advantages of KNN\n",
    "\n",
    "-- Does not work well with large dataset:\n",
    "\n",
    "-- Does not work well with high dimensions:\n",
    "    \n",
    "-- Need feature scaling.\n",
    "\n",
    "-- Sensitive to noisy data, missing values and outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b285f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8ac13a",
   "metadata": {},
   "source": [
    "-- Euclidean distance is the shortest path between source and destination which is a straight line. \n",
    "\n",
    "-- Manhattan distance is sum of all the real distances between source(s) and destination(d) and each distance are always the straight line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139e11f6",
   "metadata": {},
   "source": [
    "#### Feature scaling is essential for machine learning algorithms that calculate distances between data. If not scaled, the feature with a higher value range starts dominating when calculating distances. KNN which uses Euclidean distance is one such algorithm which essentially require scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
