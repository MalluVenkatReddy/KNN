{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1990a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in \n",
    "sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f92c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  1 11]]\n",
      "0.9777777777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x,y=load_iris(return_X_y=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=0)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4510c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in \n",
    "sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c7f0c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5748334691810936\n",
      "4.148862275449102\n",
      "32.17596886227545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "X,y=load_boston(return_X_y=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "regressor=KNeighborsRegressor()\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred=regressor.predict(X_test)\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3789ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using \n",
    "cross-validation on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "27ee869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x,y=load_iris(return_X_y=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=0)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "29d31de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hypeparameter Tuning\n",
    "params={'n_neighbors':[3,5,10,100],\n",
    "              'algorithm':['ball_tree','kd_tree'],\n",
    "               'p':[1,2]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca1a31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "afc5649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_cls=RandomizedSearchCV(classifier,param_distributions=params,scoring='accuracy',cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "acdbede5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END algorithm=kd_tree, n_neighbors=10, p=1;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, n_neighbors=10, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, n_neighbors=10, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, n_neighbors=10, p=1;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, n_neighbors=10, p=1;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, n_neighbors=3, p=2;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, n_neighbors=3, p=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, n_neighbors=3, p=2;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, n_neighbors=3, p=2;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, n_neighbors=3, p=2;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, n_neighbors=5, p=2;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, n_neighbors=5, p=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, n_neighbors=5, p=2;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, n_neighbors=5, p=2;, score=0.857 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, n_neighbors=5, p=2;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, n_neighbors=5, p=1;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, n_neighbors=5, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, n_neighbors=5, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, n_neighbors=5, p=1;, score=0.857 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, n_neighbors=5, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, n_neighbors=3, p=1;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, n_neighbors=3, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, n_neighbors=3, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, n_neighbors=3, p=1;, score=0.857 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, n_neighbors=3, p=1;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, n_neighbors=3, p=1;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, n_neighbors=3, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, n_neighbors=3, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, n_neighbors=3, p=1;, score=0.857 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, n_neighbors=3, p=1;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, n_neighbors=10, p=2;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, n_neighbors=10, p=2;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, n_neighbors=10, p=2;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, n_neighbors=10, p=2;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, n_neighbors=10, p=2;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, n_neighbors=10, p=1;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, n_neighbors=10, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, n_neighbors=10, p=1;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, n_neighbors=10, p=1;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, n_neighbors=10, p=1;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, n_neighbors=100, p=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, n_neighbors=100, p=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, n_neighbors=100, p=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, n_neighbors=100, p=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, n_neighbors=100, p=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, n_neighbors=100, p=2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, n_neighbors=100, p=2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, n_neighbors=100, p=2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, n_neighbors=100, p=2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, n_neighbors=100, p=2;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 214, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 84, n_neighbors = 100\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 214, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 84, n_neighbors = 100\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 214, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 84, n_neighbors = 100\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 214, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 84, n_neighbors = 100\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 214, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 84, n_neighbors = 100\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 214, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 84, n_neighbors = 100\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 214, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 84, n_neighbors = 100\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 214, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 84, n_neighbors = 100\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 214, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 84, n_neighbors = 100\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 214, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 84, n_neighbors = 100\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.96190476 0.94285714 0.96190476 0.95238095 0.94285714 0.94285714\n",
      " 0.96190476 0.96190476        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "                   param_distributions={'algorithm': ['ball_tree', 'kd_tree'],\n",
       "                                        'n_neighbors': [3, 5, 10, 100],\n",
       "                                        'p': [1, 2]},\n",
       "                   scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_cls.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "caa04bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': 2, 'n_neighbors': 5, 'algorithm': 'kd_tree'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_cls.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25787710",
   "metadata": {},
   "source": [
    "### Optimum value of k is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in \n",
    "sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2e4daff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7467624886127056\n",
      "2.7128143712574846\n",
      "19.164637125748506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mallu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "X,y=load_boston(return_X_y=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar=StandardScaler()\n",
    "X_train=scalar.fit_transform(X_train)\n",
    "X_test=scalar.fit_transform(X_test)\n",
    "\n",
    "regressor=KNeighborsRegressor()\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred=regressor.predict(X_test)\n",
    "\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d80e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write a Python code snippet to implement the KNN classifier algorithm with weighted voting on \n",
    "load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a486cd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  1 11]]\n",
      "0.9777777777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x,y=load_iris(return_X_y=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=0)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier(weights='distance')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Implement a function to standardise the features before applying KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "304dd298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  5 11]]\n",
      "0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.72      1.00      0.84        13\n",
      "           2       1.00      0.69      0.81        16\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.91      0.90      0.88        45\n",
      "weighted avg       0.92      0.89      0.89        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x,y=load_iris(return_X_y=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=0)\n",
    "\n",
    "scalar=StandardScaler()\n",
    "X_train=scalar.fit_transform(X_train)\n",
    "X_test=scalar.fit_transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier(weights='distance')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb85449",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Write a Python function to calculate the euclidean distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26e1e05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.486832980505138\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "p = [3, 3]\n",
    "q = [6, 12]\n",
    "\n",
    "print (math.dist(p, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ade22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Write a Python function to calculate the manhattan distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "p = [3, 3]\n",
    "q = [6, 12]\n",
    "\n",
    "print (math.dist(p, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7e27d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Manhattan Distance from Scratch\n",
    "def manhattan_distance(point1, point2):\n",
    "    distance = 0\n",
    "    for x1, x2 in zip(point1, point2):\n",
    "        difference = x2 - x1\n",
    "        absolute_difference = abs(difference)\n",
    "        distance += absolute_difference\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd73b2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan_distance(p, q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
